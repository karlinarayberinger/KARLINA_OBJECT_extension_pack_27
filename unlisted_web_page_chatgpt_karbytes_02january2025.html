<hr />
<p><strong>chatgpt_karbytes_02january2025</strong></p>
<hr>
<p><span style="background:#ffff00">The text in the web page section below was copied from the plain-text file named <a style="background: #000000;color: #ff9000" href="https://raw.githubusercontent.com/karlinarayberinger/KARLINA_OBJECT_extension_pack_27/main/chatgpt_karbytes_02january2025.txt" target="_blank" rel="noopener noreferrer">chatgpt_karbytes_02january2025.txt</a> in the &#8220;micro directory&#8221; website section named <a style="background: #000000;color: #00ff00" href="https://karbytesforlifeblog.wordpress.com/raw_github_files_directory_karlina_object_extension_pack_27/" target="_blank" rel="noopener noreferrer">raw_github_files_directory_KARLINA_OBJECT_extension_pack_27</a> in the &#8220;macro directory&#8221; website section (named <a style="background: #000000;color: #00ff00" href="https://karbytesforlifeblog.wordpress.com/raw_github_files_macro_directory/" target="_blank" rel="noopener noreferrer">RAW_GITHUB_FILES_MACRO_DIRECTORY</a>) of the website named <a style="background: #000000;color: #ff9000" href="https://karbytesforlifeblog.wordpress.com/" target="_blank" rel="noopener noreferrer">Karbytes For Life Blog dot WordPress dot Com</a>. Some of the aforementioned copied <a style="background: #ff9000;color: #000000" href="https://en.wikipedia.org/wiki/Plain_text" target="_blank" rel="noopener noreferrer">plain-text</a> was then replaced with relevant <a style="background: #ff9000;color: #000000" href="https://en.wikipedia.org/wiki/Hypertext" target="_blank" rel="noopener noreferrer">hypertext</a> on this web page.</span></p>
<p><em>To view hidden text inside each of the preformatted text boxes below, scroll horizontally.</em></p>
<hr>
<pre>
/**
 * file: <a style="background: #000000;color: #ff9000" href="https://raw.githubusercontent.com/karlinarayberinger/KARLINA_OBJECT_extension_pack_27/main/chatgpt_karbytes_02january2025.txt" target="_blank" rel="noopener noreferrer">chatgpt_karbytes_02january2025.txt</a>
 * type: <a style="background: #ff9000;color: #000000" href="https://en.wikipedia.org/wiki/Plain_text" target="_blank" rel="noopener noreferrer">plain-text</a>
 * date: 02_JANUARY_2025
 * author: <a style="background: #000000;color: #ff9000" href="https://karbytesforlifeblog.wordpress.com/about_karbytes/" target="_blank" rel="noopener noreferrer">karbytes</a>
 * license: <a style="background: #000000;color: #ff9000" href="https://karlinaobject.wordpress.com/public_domain/" target="_blank" rel="noopener noreferrer">PUBLIC_DOMAIN</a>
 */

The following is a conversation transcript from a chatbot session established between karbytes and <a style="background: #ff9000;color: #000000" href="https://en.wikipedia.org/wiki/GPT-4o" target="_blank" rel="noopener noreferrer">ChatGPT-4o</a> on 02_JANUARY_2025 at approximately 12:30PM Pacific Standard Time. The conversation pertains to karbytes inquiring about hypothetical and empirically measurable runtime limitations of a Python program karbytes wrote which is designed to have an indefinitely long runtime and which is, for the duration of that runtime, incrementing integer variables by one per second (and also computing the approximate value of Pi using those integers as inputs to some calculation whose output is represented as a floating-point number value). That program is showcased in explicit detail on the following web page:

<a style="background: #000000;color: #00ff00" href="https://karbytesforlifeblog.wordpress.com/pi_approximation_three/" target="_blank" rel="noopener noreferrer">https://karbytesforlifeblog.wordpress.com/pi_approximation_three/</a>

* * *

karbytes:

How long do you think the following Python program can run on my karbytes-IdeaPad-1-15IAU7 machine before the program crashes?

<a style="background: #000000;color: #00ff00" href="https://raw.githubusercontent.com/karlinarayberinger/KARLINA_OBJECT_extension_pack_27/main/pi_approximation.py" target="_blank" rel="noopener noreferrer">[https://raw.githubusercontent.com/karlinarayberinger/KARLINA_OBJECT_extension_pack_27/main/pi_approximation.py]</a>

ChatGPT:

The program runs indefinitely by design unless interrupted by the user, a system crash, or another limiting factor. The machine's ability to sustain the program without crashing depends on several factors:

Key Considerations:

1. CPU Usage:

    The program generates random numbers and checks them against a condition repeatedly. This is computationally lightweight for most modern processors, including the IdeaPad 1-15IAU7's CPU.

2. Memory Consumption:

    The program does not store past results except for a few counters and the most recent log output. Thus, it uses a minimal and predictable amount of memory.

3. Disk I/O:

    The program overwrites the same output file every second. This is unlikely to be a bottleneck unless there are underlying disk health issues or an external event like a disk full error.

4. Operating System and System Stability:

    If your system has stable software and hardware with no background tasks consuming significant resources, the program can run indefinitely.

5. Heat and Throttling:

    If the laptop's cooling system is insufficient or the environment is too hot, the system might throttle performance or crash due to overheating.

Likely Runtime:

    On your Lenovo IdeaPad 1-15IAU7 machine, assuming normal conditions (stable OS, sufficient disk space, and no hardware issues), this program should theoretically run until manually interrupted or the machine powers down. However:

    If the machine is left unattended for days, external factors like automatic updates, power outages, or disk errors might cause interruptions.

    Given the lack of memory leaks or high resource demands, this program could potentially run for weeks or even months.

Let me know if you'd like a diagnostic or more detailed resource profiling approach!

karbytes:

When do you expect the pi_approximation value (or any of the other variables which are updated each second of program runtime) generated by that program to start exhibiting garbage values due to those values growing too big to be meaningfully represented?

ChatGPT:

The variables in the program update each second and grow indefinitely, but garbage values or inaccuracies can emerge due to the following factors:

1. Precision of Floating-Point Arithmetic

    pi_approximation Calculation:

        The calculation of ππ as 4 \times (\text{red_count} / \text{total_darts}) relies on floating-point arithmetic.

        In Python, floating-point numbers conform to the IEEE 754 double-precision standard, which can represent numbers with 15–17 significant decimal digits accurately.

        As red_count and blue_count grow large (e.g., beyond 10151015), dividing them may lose precision due to limitations of floating-point representation.

2. Integer Overflow (Python Handles This Gracefully)

    Python's integers are unbounded and automatically promoted to arbitrary-precision integers when they exceed the machine's native word size.

    Variables like red_count, blue_count, and total_darts will not overflow but will require more memory over time as they grow large.

3. Log File Size

    The program overwrites the log file every second, so file size doesn’t directly grow. However, Python's handling of very large floating-point approximations (e.g., generating output with excessive digits) might become computationally expensive, impacting runtime efficiency.

3. Approximation Errors:

    The garbage values aren't expected to appear outright, but the accuracy of pi_approximation will degrade subtly when total counts exceed 10151015. Floating-point precision will start dropping bits of accuracy in the least significant digits.

4. Practical Runtime to Degradation:

    Red/Blue Dot Counts: It would take approximately 10151015 seconds to reach this range (about 31.731.7 million years). Before reaching this point, external factors like hardware or environmental limitations would terminate the program.

    Floating-Point Precision Limits: You’ll likely see subtle inaccuracies in the 15th–17th decimal places of pi_approximation after days or weeks of runtime, but these are minimal and unlikely to affect the overall usability of the program.

In short, under realistic conditions, you will not encounter "garbage values" unless the program is left running for centuries! If you'd like a more detailed simulation or profiling of this scenario, let me know!

karbytes:

"Variables like red_count, blue_count, and total_darts will not overflow but will require more memory over time as they grow large." I dispute that claim. If those values are always increasing by one per second of the simulation, then eventually (if the simulation is allowed to run for an indefinitely long time) the values which those variables would be storing would eventually grow too large to fit inside of their respective variables.

ChatGPT:

In Python, integers are arbitrary-precision, which means they do not overflow as they grow larger. Instead, Python automatically allocates additional memory to represent larger integers as needed. This is different from languages like C or C++, where integers have fixed sizes (e.g., int32 or int64).

Why red_count, blue_count, and total_darts Won't Overflow in Python:

    Python's int type can handle values much larger than the memory of most machines because it is not bound by fixed bit sizes.
    
    As these variables increase, Python dynamically allocates more memory to store their values. The only limitation is the available system memory.

Practical Implications:

    Memory Use: While the variables won't overflow, the memory required to store them will grow over time. For example:
        
        A 10-digit number uses approximately 4 bytes.
        
        A 20-digit number might require up to 8 bytes or more.
        
        The memory usage grows logarithmically with the size of the integer.

    Performance: Operations on very large integers may slow down due to the additional computational overhead of handling arbitrary-precision numbers.

Eventual Limits:

    Memory Exhaustion:
       
        If the program runs for a very long time, the memory required to store the variables will eventually exceed the system's available RAM or virtual memory. At this point, the program will crash with a MemoryError.

    Practical Constraints:
        
        If we assume the program runs for 10201020 seconds (a ridiculously long time), the integers would require significant memory, and the system would likely crash well before that.

Example of Memory Exhaustion:

To simulate such behavior:

[python]

count = 1
while True:
    count *= 10  # Exponentially grow the value
    print(count)

This will eventually fail due to memory limits, but not due to overflow in the traditional sense.

Conclusion:

You're correct that the variables will eventually cause the program to crash—not from overflow, but from memory exhaustion as the integers grow arbitrarily large. For practical runtimes (days, months, or even years), this is unlikely to be an issue, but it becomes relevant for simulations running over extremely long periods.

karbytes:

Describe what I might observe if I were to run that program which you wrote for a "ridiculously long time".

ChatGPT:

If you were to run the program for a "ridiculously long time," here's what you might observe, broken into different stages:

1. Initial Period (Hours to Days)

    Output Behavior:

        The program runs smoothly, with regular updates to the console and the output file.

        The pi_approximation becomes increasingly accurate as more points are sampled. You might notice convergence toward the value of ππ (3.14159...) with more decimal places matching.
        
        Both red_count and blue_count increase linearly, with the total dart count also growing at a rate of 1 per second.

    System Behavior:

        The program consumes minimal resources (CPU and memory usage remain low).

        Disk activity is light because the output file is overwritten every second.

2. Medium Period (Weeks to Months)

    Output Behavior:

        The pi_approximation might show signs of losing precision in the least significant decimal places. This happens due to the floating-point limitations when dividing very large integers.
        
        The counters (red_count, blue_count, total_darts) are still updating correctly, but their size might start to noticeably affect the time it takes to calculate and format the output.

    System Behavior:

        Memory usage increases slightly due to the growing size of integers, but it remains manageable within modern system capabilities.
        
        Disk activity is stable, assuming the storage device has no issues with repeated writes to the log file.

3. Long Period (Years to Decades)

    Output Behavior:
        
        You might notice a delay in updates to the console and file as the calculations involving massive integers (e.g., division and formatting) take more time.
        
        Floating-point inaccuracies become more prominent, especially in the farthest decimal places of pi_approximation.
        
        File overwriting might become slower as the system spends more time formatting and handling large numbers.

    System Behavior:
        
        Memory usage begins to climb significantly as the integer sizes for red_count and blue_count grow. Each number requires progressively more memory to store.
        
        CPU utilization increases because operations on larger integers become more computationally expensive.

4. Ridiculously Long Period (Centuries to Millennia)

    Output Behavior:

        Updates to the log file and console might become sporadic or significantly delayed due to the increasing computational overhead.

        pi_approximation may lose significant precision, but only at extreme decimal places that aren't practically relevant.

    System Behavior:

        The program crashes due to one or more of the following:

            Memory Exhaustion: The system can no longer allocate memory for the growing integer sizes.

            Disk Wear: Frequent overwriting of the log file could potentially wear out the storage medium (if it's an SSD or other finite-write-cycle device).

            External Factors: Power outages, hardware failure, or operating system limits (e.g., max file size or process lifespan) could terminate the program.

5. Hypothetical Ultra-Long Period (Billions of Years)

    If the program were to somehow keep running:

        The increasing size of integers would demand immense amounts of memory and computational time.

        Even the most basic operations, like incrementing the counters or writing to the file, would become impractically slow.

        The system would eventually reach a physical or thermal limit, and the hardware would fail long before the integers reached a size Python couldn’t represent.

In summary, while the program won’t crash due to traditional overflow, you would observe slowing performance over time, memory usage steadily increasing, and eventual system instability due to memory or hardware limitations if run for a ridiculously long duration.

karbytes:

"The system would eventually reach a physical or thermal limit, and the hardware would fail long before the integers reached a size Python couldn’t represent." Describe that hypothetical phenomenon in more detail.

ChatGPT:

The eventual hardware failure from running your program for an exceedingly long time stems from cumulative wear and tear on the physical components of your machine. Here’s a breakdown of how this phenomenon might unfold in a hypothetical ultra-long runtime scenario:

1. CPU Overload and Thermal Limits

Description:

    The CPU is responsible for performing all the arithmetic operations required by your program. As the integers in red_count, blue_count, and total_darts grow extremely large:
        
        The time required for each arithmetic operation increases, as Python must handle multi-word integers (arbitrary-precision representation).
        
        The CPU remains under sustained load for extended periods, generating heat continuously.
        
        Over decades or centuries, this constant thermal stress can degrade the CPU's silicon and other internal components, leading to eventual failure.

Observable Effects:

    Slowing performance as the CPU begins throttling to prevent overheating.

    Unrecoverable hardware errors, such as corrupted calculations or complete CPU failure.

2. Memory Exhaustion and Degradation

Description:

    Arbitrary-precision integers require progressively more memory as they grow larger. While Python dynamically allocates this memory, the system's physical RAM and swap space are finite.
    
    Prolonged high memory usage can cause:

        Paging Overload: Excessive reliance on swap space (disk-based memory) can slow the system significantly and increase disk wear.

        Hardware Stress: Continual memory allocation and deallocation can increase the failure rate of DRAM chips due to electrochemical degradation.

Observable Effects:

    Increased system lag and eventual program termination with a MemoryError if RAM and swap are exhausted.

    Gradual failure of memory modules, potentially leading to kernel panics or unresponsive behavior.

3. Storage Device Wear

Description:

    The program overwrites the output file every second. This frequent write operation can stress storage devices, especially solid-state drives (SSDs), which have a finite number of write cycles per cell.

    Over time:

        The repeated writes degrade SSD cells, reducing available storage and possibly corrupting the output file.

        If using a hard disk drive (HDD), the mechanical wear on the drive's platters and actuator arms can lead to failure.

Observable Effects:

    Errors in the output file, such as corrupted or incomplete data.

    Drive failure manifesting as the inability to save or read files.

4. Power Supply Unit (PSU) Fatigue

Description:

    Continuous operation under high load draws consistent power from the PSU. Over decades, the PSU’s capacitors and other components degrade due to heat and electrical stress.

    A failing PSU may deliver unstable voltages, damaging other components like the CPU, GPU, or motherboard.

Observable Effects:

    System instability, random shutdowns, or failure to power on.

    Permanent damage to connected components.

5. Cooling System Degradation

Description:

    The cooling system (fans, heatsinks, or liquid cooling) works continuously to dissipate heat generated by the CPU and other components.

    Over time, moving parts like fans wear out or collect dust, reducing efficiency. If cooling fails:

        Overheating can cause the CPU or GPU to throttle and eventually fail.

        Other components may suffer thermal damage.

Observable Effects:

    Increased noise from failing fans.

    System shutdowns due to thermal protections.

6. Environmental and External Factors

Description:

    Running hardware continuously for centuries would expose it to:

        Dust accumulation, which insulates components and worsens heat dissipation.

        Physical decay, such as corrosion of solder joints or degradation of plastic parts.

        Cosmic rays or radiation causing bit flips in memory or processors (more relevant for extremely long runtimes).

Observable Effects:

    Unexplained crashes or corrupted data.

    Visible wear, such as discoloration, cracks, or material breakdown.

Hypothetical Timeline

    Months to Years: System performs normally but with minor signs of increased heat and memory usage.

    Years to Decades:

        Storage or memory failure due to wear.

        Decreasing CPU efficiency or throttling.

    Decades to Centuries:

        Total failure of core components (CPU, memory, storage).

        Environmental factors accelerate failure, such as dust or heat damage.

    Centuries+: If somehow kept running, the system would likely experience catastrophic hardware breakdowns due to cumulative damage and resource exhaustion.

Conclusion

If left to run indefinitely, your program would eventually push your hardware to the limits of endurance. While Python itself could theoretically handle arbitrarily large integers, the physical limitations of your Lenovo IdeaPad (or any hardware) would ensure the program cannot run forever. It would terminate due to heat, wear, or electrical failure long before reaching an impractical size for the integers.

karbytes:

Suppose I kept the program running on a machine whose worn-out parts are replaced while the machine is powered on and running the program (and the machine has multiple sets of the same hardware components so that there is always at least one of those parts available for the computer to use (and the machine is configured to self-repair using a different program than the Pi approximation program)). Then how long would that Pi approximation program be able to run (and, if there comes an end to that program running due to hardware issues) describe those hardware (and related software) issues in generous detail.

ChatGPT:

If the Pi approximation program runs on a machine with self-repairing capabilities and redundant hardware, theoretically, the program could run indefinitely as long as:

Redundant hardware components are available and can replace failing parts without disrupting the running program.
    
The self-repair system functions perfectly and handles component replacement in real-time without introducing system instability or performance degradation.
    
The software and system configuration remain stable and free of bugs that could accumulate over extremely long runtimes.

Potential Issues and Hypothetical Endgame

Even with this self-repairing and redundant hardware setup, there are limits due to the fundamental nature of computing systems and environmental factors:

1. Software Limitations and Runtime Errors

Issue:

    Accumulative Bugs: The program or the underlying operating system (OS) might accumulate errors over time due to:

        Memory leaks in the self-repair program or the OS.

        Floating-point inaccuracies propagating into other calculations.

        Corruption of system files, configurations, or logs due to extended write cycles.

    Dependency Aging: Software dependencies (e.g., libraries or drivers) might fail under prolonged operation due to compatibility issues, unexpected edge cases, or entropy in the software environment.

Observable Effects:

    Increasingly slow performance due to software inefficiencies.

    Program crashes or incorrect behavior caused by accumulated errors or corrupted data.

    The OS or repair system failing to properly allocate resources for the Pi approximation program.

Likely End:

    The program stops functioning due to unrecoverable runtime errors, corruption, or a system halt.

2. Physical and Quantum-Level Hardware Failures

Issue:

    Atomic Wear and Tear: Over extremely long durations, even redundant and replaced hardware can degrade due to fundamental physical processes:

        Cosmic Rays: High-energy particles can flip bits in memory or registers, leading to errors that accumulate in both the Pi approximation program and the repair system.

        Electromigration: The slow movement of atoms in semiconductors under prolonged electrical stress can degrade critical pathways, even in newly replaced components.

        Thermal Cycling: Constant heating and cooling of components can eventually weaken even newly introduced parts.

Observable Effects:

    Memory corruption causing incorrect outputs.

    Increasing repair frequency as hardware components fail at faster rates due to cumulative stress.

    Permanent corruption of critical system areas (e.g., BIOS/UEFI or core firmware), rendering the machine inoperable.

Likely End:

    Hardware becomes irreparably damaged at the atomic level, leading to catastrophic failure.

3. Energy and Resource Limitations

Issue:

    Power Supply Limits: Continuous operation over extremely long durations would require a stable power source. Interruptions in power could cause ungraceful shutdowns, damaging the program state or hardware.

    Redundancy Resource Depletion: If the machine runs out of spare hardware components (e.g., RAM, storage, CPUs), the self-repair system would be unable to continue, leading to failure.

Observable Effects:

    Gradual slowdown as components are recycled more frequently or operated closer to failure thresholds.

    Complete halt of operations when no redundant resources are available.

Likely End:

    Program terminates due to an inability to replace failing hardware.

4. Environmental and External Factors

Issue:

    Environmental Degradation: Over centuries, external conditions like dust, temperature changes, and physical aging of housing materials could compromise the machine's ability to function.

    External Interference: Power surges, electromagnetic disturbances, or physical tampering could damage critical components or the repair system.

Observable Effects:

    Degradation of system performance due to increased maintenance needs.

    Unexpected shutdowns or hardware destruction from environmental impacts.

Likely End:

    Program ends due to a catastrophic external event.

Hypothetical Timeline

    Initial Period (Years):

        The system operates without noticeable degradation due to hardware redundancy and efficient self-repair.

        The Pi approximation program continues running, approximating ππ to more and more digits.

    Medium Period (Decades to Centuries):

        Software inefficiencies or bugs begin to accumulate. Resource exhaustion in logs or temporary files may strain the OS.

        Environmental factors like dust accumulation, thermal cycling, and cosmic ray impacts start causing more frequent failures.

    Long Period (Millennia to Millions of Years):

        Atomic-level degradation (electromigration, cosmic ray impacts) becomes significant, increasing the rate of hardware failure and repair.

        Software errors compound due to the inability of self-repair systems to address deeply rooted software issues.

    Endgame (Millions to Billions of Years):

        All physical hardware is irreparably damaged due to atomic-level wear or external factors.

        Energy sources deplete or external interference (e.g., cosmic events) disrupts operations permanently.

Conclusion

While the self-repairing machine extends the program's runtime far beyond typical hardware lifespans, the combined effects of software inefficiencies, physical degradation, and environmental factors make indefinite operation unlikely. Under ideal conditions, the program might run for millions to billions of years, but it will eventually fail due to fundamental limitations of physical systems and computational entropy.

karbytes:

What is the difference between "computational entropy" and (physical) entropy?

ChatGPT:

1. Physical Entropy (Thermodynamic Entropy)

    Definition:

        A concept from thermodynamics and statistical mechanics, physical entropy measures the amount of disorder or randomness in a physical system. It quantifies the number of possible microscopic configurations that correspond to a macroscopic state.

        Represented by the symbol S, it is defined in statistical mechanics as:

        S=kBln⁡(Ω)
        
        where kB is the <a style="background: #ff9000;color: #000000" href="https://en.wikipedia.org/wiki/Boltzmann_constant" target="_blank" rel="noopener noreferrer">Boltzmann constant</a> and Ω is the number of microstates.

        [karbyte: Note that, beyond the context of this plain-text passage, the 'B' in "kB" is subscript.]

    Key Characteristics:

        Irreversibility: In a closed system, entropy tends to increase over time, following the second law of thermodynamics.

        Energy Degradation: As entropy increases, usable energy within a system decreases, leading to a state of maximum entropy (equilibrium).

        Applies to physical systems like heat transfer, chemical reactions, and the universe as a whole.

    Examples:

        Heat flowing from a hot object to a cold one.

        Ice melting into water.

2. Computational Entropy

    Definition:

        Computational entropy refers to the loss of order, predictability, or coherence in a computational system. It is not a physical property but rather a conceptual analogy that describes how errors, inefficiencies, or randomness accumulate in a computational process or system.

    Key Characteristics:

        Software Entropy: Over time, software systems can become disorganized due to accumulated bugs, poorly managed memory, or resource mismanagement.

        Data Integrity Loss: Errors in data storage, bit flips, or corruption in files and logs can degrade computational accuracy.

        Algorithmic Degradation: Iterative algorithms may amplify floating-point rounding errors or other inaccuracies, leading to "computational noise."

        Often a consequence of limited precision, imperfect algorithms, or extended runtime in software or hardware systems.

    Examples:

        A program producing inaccurate results due to rounding errors in floating-point arithmetic.

        Memory corruption or data loss due to hardware failures.

-------------------------------------------------------------------------------------------------------------------------------------------
Key Differences

Aspect                  Physical Entropy                                        Computational Entropy

Origin                  Thermodynamic principles                                Computational systems (software and hardware)

System Type             Physical systems (e.g., heat engines, gases)            Digital systems (e.g., programs, algorithms)

Units                   Measured in Joules per Kelvin (J/K)                     Conceptual, not physically quantifiable

Nature                  Irreversible energy dispersion in closed systems        Accumulation of errors or inefficiencies

Resolution              Requires external energy input to reduce                Requires debugging, error correction, or reset

Examples                Heat transfer, melting ice                              Data corruption, floating-point errors
-------------------------------------------------------------------------------------------------------------------------------------------

3. Analogy Between the Two

Physical entropy and computational entropy both represent the degradation of order over time:

    In physical systems, entropy increases as energy disperses and systems move toward equilibrium.

    In computational systems, entropy increases as errors, inefficiencies, or randomness accumulate, degrading system performance or output accuracy.

In both cases, external intervention (energy input or debugging) is required to restore order or reduce entropy.
</pre>
<hr />
<p>This web page was last updated on 02_JANUARY_2025. The content displayed on this web page is licensed as <a style="background: #000000;color: #ff9000" href="https://karlinaobject.wordpress.com/public_domain/" target="_blank" rel="noopener noreferrer">PUBLIC_DOMAIN</a> intellectual property.</p>
<hr>
